package scalan.math

import scalan.sequential.ScalanSeq
import scalan.staged.ScalanStaged

trait MatricesOps { scalan: MatricesDsl =>

  trait MatrixOps[A] extends Matrix[A] {
    def fromCellIndex(iCell: Rep[Int]): Rep[(Int, Int)] = Pair(iCell / numColumns, iCell % numColumns)
    def toCellIndex(iRow: Rep[Int], iCol: Rep[Int]): Rep[Int] = numColumns * iRow + iCol
    def row(iRow: Rep[Int]): Rep[DenseVector[A]] = apply(iRow)
  }
  trait DenseMatrixOps[A] extends MatrixOps[A] {
    def numRows = items.length / numColumns
    
    //Expands to: ((is *^ scale).expandByLengths(replicate(n, scale))).values +^ replicate(n, indexRange(scale)).values
    def rowsCellIndices(is: PA[Int]): PA[Int] = {
      val n = is.length
      val starts = is *^ numColumns
      val ranges = replicate(n, indexRange(numColumns))
      val scaledRanges = for { Pair(s, r) <- starts zip ranges } yield r +^ s
      scaledRanges.values
    }

    def blockCellIndices(top: Rep[Int], left: Rep[Int], height: Rep[Int], width: Rep[Int]): PA[Int] = {
      for {
        i: Rep[Int] @unchecked <- indexRange(height)
        j <- indexRange(width)
      } yield {
        toCellIndex(top + i, left + j)
      }
    }

    def transposeIndices(is: PA[Int]): PA[Int] = {
      for { i <- is } yield {
        val Pair(iRow, iCol) = fromCellIndex(i)
        val transM = DenseMatrix(items, numRows)
        transM.toCellIndex(iCol, iRow)
      }
    }

    def ->>(is: PA[Int]): Rep[DenseMatrix[A]] = {
      val selectedRows = rows ->> is
      DenseMatrix(selectedRows.map(_.items).values, numColumns)
    }

    def getTranspositionOfBlocks(blocks: PA[((Int, Int), (Int, Int))]): PA[(Int, Int)] = {
      val res = for { Pair(Pair(top, left), Pair(height, width)) <- blocks } yield {
        val bcis = blockCellIndices(top, left, height, width)
        val trans = transposeIndices(bcis)
        bcis zip trans
      }
      res.values
    }

    def transpose(blockSize: Rep[Int] = toRep(10)): Rep[DenseMatrix[A]] = {
      val n = (numRows - 1) / blockSize + 1
      val m = (numColumns - 1) / blockSize + 1
      val bHeight = numRows % blockSize
      val rWidth = numColumns % blockSize
      val lastHeight = IF(bHeight === 0) THEN blockSize ELSE bHeight
      val lastWidth = IF (rWidth === 0) THEN blockSize ELSE rWidth

      val blocks = for {
        i: Rep[Int] @unchecked <- indexRange(n)
        j <- indexRange(m)
      } yield {
        val height: Rep[Int] = IF(i === n - 1) THEN lastHeight ELSE blockSize
        val width = IF(j === m - 1) THEN lastWidth ELSE blockSize
        Pair(Pair(i * blockSize, j * blockSize), Pair(height, width))
      }

      val is = getTranspositionOfBlocks(blocks)
      val transposedItems = items <<- (is.bs, items ->> is.as)

      DenseMatrix(transposedItems, numRows)
    }
    
    def reduceRowsBy(segLens: PA[Int])(implicit m: RepMonoid[A]): Rep[DenseMatrix[A]] = {
      //require(segLens.reduce === numColumns)
      val sums = for { row <- rows } yield row.items.nestByLengths(segLens).reduceSeg
      DenseMatrix(sums.values, numColumns)
    }

    /**
     * For each row reduce elements into specified columns(cols) from column groups given by nested array(colGroups) applying monoid operation along the way
     * length(this) == length(res)
     * length(cols) == length(colGroups)
     * rows(i)(col(j)) = sum(rows(i) ->> colGroup(j))
     * @param cols specifies the columns to append (up to monoid) elements from other columns given by each column group
     * @param colGroups columns in this matrix grouped into nested structure
     * @param m  monoid operation to apply to elements that fall at the same column
     */
    def permuteReduceTransposedRowsByNested(cols: PA[Int], colGroups: NA[Int])(implicit m: RepMonoid[A]): Rep[DenseMatrix[A]] = {
      //require(segLens.reduce === numColumns)
      val newRows =
        for { row <- rows } yield {
          val vs = for { g <- colGroups } yield (row ->> g)
          row.items.permuteReduceNested(cols, vs)
        }
      DenseMatrix(newRows.values, numColumns)
    }

    def <<-(iRows: PA[Int], xss: Rep[Matrix[A]]): Rep[DenseMatrix[A]] = {
      val newItems = items <<- (rowsCellIndices(iRows), xss.items)
      DenseMatrix(newItems, numColumns)
    }

    def permuteReduceRows(targetRows: PA[Int], subMatrix: Rep[DenseMatrix[A]], segLens: PA[Int])(implicit m: RepMonoid[A]): Rep[DenseMatrix[A]] = {
      val lSegs = createSegmentsFromLens(segLens)

      val idxs_for_reduce = (for (p1 <- lSegs) yield {
        val t1 = (indexRange(p1._2) +^ p1._1) *^ numColumns
        val t2 = (indexRange(numColumns) map (p2 => t1 +^ p2))
        t2
      }).values
      /* Rearrange subMatrix items for reducing */
      val vals_for_reduce = (subMatrix.items ->> idxs_for_reduce.values).nestBy(idxs_for_reduce.segments)

      val newItems = items.permuteReduceNested(rowsCellIndices(targetRows), vals_for_reduce)
      DenseMatrix(newItems, numColumns)
    }
    
    def apply(row: Rep[Int]): Rep[DenseVector[A]] = DenseVector(items.slice(numColumns * row, numColumns))
    def apply(row: Rep[Int], column: Rep[Int]) = items(toCellIndex(row, column))
    def rows = items.nestByLengths(replicate(numRows, numColumns)).map(DenseVector(_))
    
    // TODO reuse dense vector/sparse vector
    def sparseRows = rows.map { row =>
      SparseVector(row.nonZeroItems, row.length)
    }
    
    def column(i: Rep[Int]): PA[A] = {
      val indexes = (indexRange(numRows) *^ numColumns) +^ i
      items ->> indexes
    }

    // inplace update of this.items
    def invert: Rep[Matrix[A]] = {
      val newItems = DenseMatrix.invert(items, numColumns)
      DenseMatrix(newItems, numColumns)
    }

  }
  trait DenseMatrixCompanion {
    def fromNA[A: Elem](rows: NA[A])(implicit o: Overloaded1): Rep[DenseMatrix[A]] = DenseMatrix(rows.values, rows(0).length)
    def invert[A:Elem](items: PA[A], numColumns: Rep[Int]): PA[A] = invertDenseMatrix(items, numColumns)
  }

  // inplace update of items
  def invertDenseMatrix[A:Elem](items: PA[A], numColumns: Rep[Int]): PA[A]

  trait ColumnSparseMatrixOps[A] extends MatrixOps[A] {
    def numRows = sparseRows.length
    def items = ???
    def apply(row: Rep[Int]): Rep[DenseVector[A]] = ???
    def apply(row: Rep[Int], column: Rep[Int]) = ???
    def rows = ???
    def invert: Rep[Matrix[A]] = ???
  }
  
  trait ColumnSparseMatrixCompanion {
    
  }

  object DenseMatrixFunctions
  {
    type D    = Double
    type DP   = Rep[D]
    type DAP  = PA[D]
    type DMP  = Rep[DenseMatrix[D]]
    type DNP  = NA[D]
    type I    = Int
    type IP   = Rep[I]
    type IAP  = PA[I]
    type B    = Boolean
    type BP   = Rep[B]

    val P0    = toRep(0)
    val P1    = toRep(1)
    val P2    = toRep(2)
    val P0D   = toRep(0.0)
    val P1D   = toRep(1.0)
    val TRUE  = toRep(true)
    val FALSE = toRep(false)
    val IndexMaxMonoid = monoid[(Int, D)]("IndexMax", (-1, Double.NegativeInfinity), true)((ix1, ix2) => IF(ix2._2 >= ix1._2) THEN ix2 ELSE ix1)

    def helperSolveParallel(luMatrix:DNP, bM:DNP):DNP =
    {
      val nLoop = bM(P0).length
      def HelperSolveLoop1(i:IP, vM:DNP) = 
      {
        val b_fA = indexRange(nLoop).map(k => 
        {         
          val lu = luMatrix(i).slice(P0, i)
          val b = vM(k).slice(P0, i)
          val lub = lu *^ b
          val lub_value = -lub.reduce
          val b_v = vM(k)(i) + lub_value
          val b_ia = singleton(i)
          val b_va = singleton(b_v)
          val b_f = vM(k) <<- (b_ia, b_va, true)
          b_f
        })
        (i + P1, b_fA)
      }
      def HelperSolveLoop2(i:IP, vM:DNP) = 
      {
        val b_fA = indexRange(nLoop).map(k => 
        {         
          val C = P1D / luMatrix(i)(i)
          val lu = luMatrix(i).slice(i + P1, nLoop - i - P1)
          val b = vM(k).slice(i + P1, nLoop - i - P1)
          val lub = lu *^ b
          val lub_value = -lub.reduce
          val b_v = (vM(k)(i) + lub_value) * C
          val b_ia = singleton(i)
          val b_va = singleton(b_v)
          val b_f = vM(k) <<- (b_ia, b_va, true)
          b_f
        })
        (i - P1, b_fA)
      }
      def HelperSolveDone1(i:IP, vM:DNP) =  i >= nLoop
      def HelperSolveDone2(i:IP, vM:DNP) =  i < P0
      val resultLoop1 = from(P1, bM).until(HelperSolveDone1)(HelperSolveLoop1)
      val b1M = resultLoop1._2.map(b =>
      {
        val i = singleton(nLoop - P1)
        val v = singleton(b(nLoop - P1) / luMatrix(nLoop - P1)(nLoop - P1))
        val b_f = b <<- (i, v, true)
        b_f
      })
      val resultLoop2 = from(nLoop - P2, b1M).until(HelperSolveDone2)(HelperSolveLoop2)
      resultLoop2._2
    }

    def inverse(matrix:DMP):(BP, DMP) = 
    {
      val rows = matrix.numRows
      val cols = matrix.numColumns
      val n = rows
      val perm = indexRange(n)

      def Decompose(matrix:DMP):(BP, DMP) = 
      {
        //val nLoop = matrix.numRows
        def DecomposeLoop(j:IP, done:BP, success:BP, matrixArray:DAP, iCols:IP) =
        {
          val matrix = DenseMatrix(matrixArray, iCols)
          val rarray = matrix.rows.map(x => x.items)
          val n_rarray = rarray.length
          val t = rarray.indexes zip rarray
          val row = rarray(j)
          val n_row = row.length
          val iRow = row.indexes
          val row2 = iRow zip row
          val vTr = row2.slice(j, n_row - j)
          val Pair(i, vMax) = vTr.reduce(IndexMaxMonoid)  // 1
          val ajj = row(j)
          val Tuple(res) = IF (ajj === P0D) THEN 
          {
            (j, TRUE, FALSE, matrixArray, n_rarray)
          } ELSE
          {
            //val vHack = P0D//IF (Math.abs(ajj) < toRep(0.0001)) THEN P1D ELSE P0D // TODO: swap rows
            val row4_1 = row.slice(j + P1, n_row - j - P1)
            val row4_2 = row4_1.map(a => a / (ajj/* + vHack*/)) // 2
            val row4_i = indexRange(n_row - j - P1) +^ (j + P1 + n_rarray * j)
            val array1 = (rarray.values) <<- (row4_i, row4_2, true)
            val array1M = DenseMatrix(array1, n_row)
            val pR_matrix = (indexRange(n_rarray - j - P1) +^ (j + P1)).map(i =>
            {
              //println("n_rarray - j - P1 = " + (n_rarray - j - P1))
              (indexRange(n_rarray - j - P1) +^ (j + P1)).map (k =>
              {
                val ik = i * n_rarray + k
                val ij = i * n_rarray + j
                val jk = j * n_rarray + k
                (ik, array1(ik) - array1(ij) * array1(jk))
              })
            })
            val pR_mtrx_flt = pR_matrix.values
            val pR_mtrx_flt_unzipped = unzip(pR_mtrx_flt)
            val array2 = array1 <<- (pR_mtrx_flt_unzipped, true)
            val result = DenseMatrix(array2, n_row)
            val isDone = (j === (n_rarray - P2))
            (j + P1, isDone, TRUE, array2, n_row)
          }
          (res._1, res._2, res._3, res._4, res._5)
        }
        def DecomposeDone(j:IP, done:BP, success:BP, matrix:DAP, iCols:IP) = done
        val tmatrix = matrix.transpose()
        val result = from(P0, FALSE, FALSE, tmatrix.rows.map(x => x.items).values, tmatrix.numColumns).until(DecomposeDone(_,_,_,_,_) === TRUE)(DecomposeLoop)
        (result._3, DenseMatrix(result._4, result._5))
      }
        
      val matrixT = matrix.transpose()
      //val resDecompose = (TRUE, matrixT)
      val resDecompose = Decompose(matrixT)
      val isDecomposed = resDecompose._1
      //println("Is Decomposed: " + isDecomposed)
      val Tuple(res/*resBool:BP, resMatrix:DMP*/) = IF (isDecomposed === FALSE) THEN
      {
        (FALSE, matrix.items, n)
      } ELSE
      {
        val lum:DMP = resDecompose._2
        val lum_T = lum.transpose()
        val bNA = indexRange(n).map(i => 
        {
          val b = indexRange(n).map(j => IF (i === perm(j)) THEN P1D ELSE P0D)
          b
        })
        val resNA = helperSolveParallel(lum_T.rows.map(x => x.items), bNA)
        //val matrix_1 = DenseMatrix(resNA.values, n)
        //val matrix_1T = matrix_1//.transpose()
        //(TRUE, matrix_1T)
        //(TRUE, lum.rows.values, n)
        (TRUE, resNA.values, n)
      }
      //(resBool, resMatrix)
      (res._1, DenseMatrix(res._2, res._3))
    }

    def sigmoid (x:DP):DP = 
    {
      P1D / (P1D + Math.exp(-x))
    }
  }
}

trait MatricesDsl extends MatricesAbs with MatricesOps with VectorsDsl

trait MatricesDslSeq extends MatricesDsl with VectorsDslSeq with MatricesSeq with ScalanSeq {
  def invertDenseMatrix[A:Elem](items: PA[A], numColumns: Rep[Int]): PA[A] = items//???//M.inverse(DenseMatrix(items, numColumns))
}

trait MatricesDslExp extends MatricesDsl with VectorsDslExp with MatricesExp with ScalanStaged {
  def invertDenseMatrix[A:Elem](items: PA[A], numColumns: Rep[Int]): PA[A] = DenseMatrixInvert(items, numColumns)

  case class  DenseMatrixInvert[A:Elem](items: PA[A], numColumns: Rep[Int]) extends StagedArrayBase[A] {
    override def mirror(f: Transformer) = DenseMatrixInvert(f(items), f(numColumns))
  }
}
